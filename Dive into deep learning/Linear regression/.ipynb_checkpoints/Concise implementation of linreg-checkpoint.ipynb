{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement linear regression by using high level api's of deep learning frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.1630785, 2.2122061]), array([-1.0015316]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from d2l import mxnet as d2l \n",
    "from mxnet import np, npx, autograd, gluon\n",
    "npx.set_np()\n",
    "\n",
    "true_w = np.array([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 1000)\n",
    "features[0], labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = gluon.data.ArrayDataset(*data_arrays)\n",
    "    return gluon.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.6076493 ,  0.51737875],\n",
       "        [ 0.5712682 ,  0.57461417],\n",
       "        [ 0.5035904 , -0.97121936],\n",
       "        [ 0.1984881 , -0.18156298],\n",
       "        [ 1.4290679 , -0.04376583],\n",
       "        [-0.36128756, -1.3773832 ],\n",
       "        [-0.89261854, -0.2328267 ],\n",
       "        [ 0.73395604,  2.739364  ],\n",
       "        [ 0.08167123,  1.1786946 ],\n",
       "        [-0.8413213 , -0.686307  ]]),\n",
       " array([[ 5.665324  ],\n",
       "        [ 3.3854222 ],\n",
       "        [ 8.518152  ],\n",
       "        [ 5.2185535 ],\n",
       "        [ 7.1972    ],\n",
       "        [ 8.150142  ],\n",
       "        [ 3.2000787 ],\n",
       "        [-3.6464229 ],\n",
       "        [ 0.35533163],\n",
       "        [ 4.837474  ]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense--defines fully connected layer \n",
    "\n",
    "our linear model has only 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing model parameters\n",
    "Initializing weight from normal distribution with mean 0 and standard deviation 0.01. \n",
    "\n",
    "Bias will be automatically initialized to 0 \n",
    "\n",
    "import initializer module from mxnet (abbrevated init)\n",
    "\n",
    "behind the scene, initialization is actually deferred and the input dimensionality information will be provided when we pass the parameters first time. Since the parameters have not been initialized yet, we cannot access or manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the loss function\n",
    "In Gluon, the loss module defines various loss functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gluon.loss.L2Loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Optimization algorithm\n",
    "Minibatch stochastic gradient descent is a standard tool for optimizing neural networks. In Gluon, the Trainer class defines number of variations on this algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':0.03})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each minibatch:\n",
    "\n",
    "    1. Generate predictions by calling net(X) and calculate loss l (the forward propagation)\n",
    "    2. Calculate gradients by running the backpropagation\n",
    "    3. Update the model parameters by invoking our optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000052\n",
      "epoch 2, loss 0.000052\n",
      "epoch 3, loss 0.000052\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(1)\n",
    "    l=loss(net(features), labels).mean()\n",
    "    print(f'epoch {epoch +1}, loss {l.asnumpy():f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in estimating b: [ 0.00093758 -0.00140834]\n",
      "error in estimating b: [0.00069189]\n"
     ]
    }
   ],
   "source": [
    "w=net[0].weight.data()\n",
    "print(f'error in estimating b: {true_w -w.reshape(true_w.shape)}')\n",
    "b = net[0].bias.data()\n",
    "print(f'error in estimating b: {true_b-b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module mxnet.gluon.nn.basic_layers object:\n",
      "\n",
      "class Sequential(mxnet.gluon.block.Block)\n",
      " |  Sequential(prefix=None, params=None)\n",
      " |  \n",
      " |  Stacks Blocks sequentially.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      net = nn.Sequential()\n",
      " |      # use net's name_scope to give child Blocks appropriate names.\n",
      " |      with net.name_scope():\n",
      " |          net.add(nn.Dense(10, activation='relu'))\n",
      " |          net.add(nn.Dense(20))\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      mxnet.gluon.block.Block\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __init__(self, prefix=None, params=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add(self, *blocks)\n",
      " |      Adds block on top of the stack.\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      Overrides to implement forward computation using :py:class:`NDArray`. Only\n",
      " |      accepts positional arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args : list of NDArray\n",
      " |          Input tensors.\n",
      " |  \n",
      " |  hybridize(self, active=True, **kwargs)\n",
      " |      Activates or deactivates `HybridBlock` s recursively. Has no effect on\n",
      " |      non-hybrid children.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      active : bool, default True\n",
      " |          Whether to turn hybrid on or off.\n",
      " |      **kwargs : string\n",
      " |          Additional flags for hybridized operator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from mxnet.gluon.block.Block:\n",
      " |  \n",
      " |  __call__(self, *args)\n",
      " |      Calls forward. Only accepts positional arguments.\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Registers parameters.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every child block as well as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fn : callable\n",
      " |          Function to be applied to each submodule, of form `fn(block)`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      this block\n",
      " |  \n",
      " |  cast(self, dtype)\n",
      " |      Cast this Block to use another data type.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype\n",
      " |          The new data type.\n",
      " |  \n",
      " |  collect_params(self, select=None)\n",
      " |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n",
      " |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n",
      " |      which match some given regular expressions.\n",
      " |      \n",
      " |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n",
      " |      'fc_bias']::\n",
      " |      \n",
      " |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n",
      " |      \n",
      " |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n",
      " |      using regular expressions::\n",
      " |      \n",
      " |          model.collect_params('.*weight|.*bias')\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      select : str\n",
      " |          regular expressions\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The selected :py:class:`ParameterDict`\n",
      " |  \n",
      " |  initialize(self, init=<mxnet.initializer.Uniform object at 0x00000214F4E1DBE0>, ctx=None, verbose=False, force_reinit=False)\n",
      " |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n",
      " |      Equivalent to ``block.collect_params().initialize(...)``\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      init : Initializer\n",
      " |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n",
      " |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n",
      " |      ctx : Context or list of Context\n",
      " |          Keeps a copy of Parameters on one or many context(s).\n",
      " |      verbose : bool, default False\n",
      " |          Whether to verbosely print out details on initialization.\n",
      " |      force_reinit : bool, default False\n",
      " |          Whether to force re-initialization if parameter is already initialized.\n",
      " |  \n",
      " |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False, cast_dtype=False, dtype_source='current')\n",
      " |      Load parameters from file previously saved by `save_parameters`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : str\n",
      " |          Path to parameter file.\n",
      " |      ctx : Context or list of Context, default cpu()\n",
      " |          Context(s) to initialize loaded parameters on.\n",
      " |      allow_missing : bool, default False\n",
      " |          Whether to silently skip loading parameters not represents in the file.\n",
      " |      ignore_extra : bool, default False\n",
      " |          Whether to silently ignore parameters from the file that are not\n",
      " |          present in this Block.\n",
      " |      cast_dtype : bool, default False\n",
      " |          Cast the data type of the NDArray loaded from the checkpoint to the dtype\n",
      " |          provided by the Parameter if any.\n",
      " |      dtype_source : str, default 'current'\n",
      " |          must be in {'current', 'saved'}\n",
      " |          Only valid if cast_dtype=True, specify the source of the dtype for casting\n",
      " |          the parameters\n",
      " |      References\n",
      " |      ----------\n",
      " |      `Saving and Loading Gluon Models         <https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html>`_\n",
      " |  \n",
      " |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n",
      " |      [Deprecated] Please use load_parameters.\n",
      " |      \n",
      " |      Load parameters from file.\n",
      " |      \n",
      " |      filename : str\n",
      " |          Path to parameter file.\n",
      " |      ctx : Context or list of Context, default cpu()\n",
      " |          Context(s) to initialize loaded parameters on.\n",
      " |      allow_missing : bool, default False\n",
      " |          Whether to silently skip loading parameters not represents in the file.\n",
      " |      ignore_extra : bool, default False\n",
      " |          Whether to silently ignore parameters from the file that are not\n",
      " |          present in this Block.\n",
      " |  \n",
      " |  name_scope(self)\n",
      " |      Returns a name space object managing a child :py:class:`Block` and parameter\n",
      " |      names. Should be used within a ``with`` statement::\n",
      " |      \n",
      " |          with self.name_scope():\n",
      " |              self.dense = nn.Dense(20)\n",
      " |      \n",
      " |      Please refer to\n",
      " |      `the naming tutorial </api/python/docs/tutorials/packages/gluon/blocks/naming.html>`_\n",
      " |      for more info on prefix and naming.\n",
      " |  \n",
      " |  register_child(self, block, name=None)\n",
      " |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n",
      " |      attributes will be registered automatically.\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the block.\n",
      " |      \n",
      " |      The hook function is called immediately after :func:`forward`.\n",
      " |      It should not modify the input or output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      hook : callable\n",
      " |          The forward hook function of form `hook(block, input, output) -> None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`mxnet.gluon.utils.HookHandle`\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the block.\n",
      " |      \n",
      " |      The hook function is called immediately before :func:`forward`.\n",
      " |      It should not modify the input or output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      hook : callable\n",
      " |          The forward hook function of form `hook(block, input) -> None`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`mxnet.gluon.utils.HookHandle`\n",
      " |  \n",
      " |  register_op_hook(self, callback, monitor_all=False)\n",
      " |      Install callback monitor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      callback : function\n",
      " |          Takes a string and a NDArrayHandle.\n",
      " |      monitor_all : bool, default False\n",
      " |          If true, monitor both input and output, otherwise monitor output only.\n",
      " |  \n",
      " |  save_parameters(self, filename, deduplicate=False)\n",
      " |      Save parameters to file.\n",
      " |      \n",
      " |      Saved parameters can only be loaded with `load_parameters`. Note that this\n",
      " |      method only saves parameters, not model structure. If you want to save\n",
      " |      model structures, please use :py:meth:`HybridBlock.export`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : str\n",
      " |          Path to file.\n",
      " |      deduplicate : bool, default False\n",
      " |          If True, save shared parameters only once. Otherwise, if a Block\n",
      " |          contains multiple sub-blocks that share parameters, each of the\n",
      " |          shared parameters will be separately saved for every sub-block.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      `Saving and Loading Gluon Models         <https://mxnet.apache.org/api/python/docs/tutorials/packages/gluon/blocks/save_load_params.html>`_\n",
      " |  \n",
      " |  save_params(self, filename)\n",
      " |      [Deprecated] Please use save_parameters. Note that if you want load\n",
      " |      from SymbolBlock later, please use export instead.\n",
      " |      \n",
      " |      Save parameters to file.\n",
      " |      \n",
      " |      filename : str\n",
      " |          Path to file.\n",
      " |  \n",
      " |  summary(self, *inputs)\n",
      " |      Print the summary of the model's output and parameters.\n",
      " |      \n",
      " |      The network must have been initialized, and must not have been hybridized.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      inputs : object\n",
      " |          Any input that the model supports. For any tensor in the input, only\n",
      " |          :class:`mxnet.ndarray.NDArray` is supported.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from mxnet.gluon.block.Block:\n",
      " |  \n",
      " |  name\n",
      " |      Name of this :py:class:`Block`, without '_' in the end.\n",
      " |  \n",
      " |  params\n",
      " |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n",
      " |      children's parameters).\n",
      " |  \n",
      " |  prefix\n",
      " |      Prefix of this :py:class:`Block`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from mxnet.gluon.block.Block:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
